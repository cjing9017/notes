# 一、为什么使用消息队列

> 消息队列使用的核心三大场景：解耦、异步、削峰

## 1.1 解耦

![1](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181057284.png)

- 有这么个场景：A系统发送数据到BCD三个系统，通过接口调用发送
- 如果此时新增了一个E系统也要这个数据，这个时候A系统就需要改代码调用E系统接口；如果此时C系统不需要了，A系统就需要改代码将调用C系统的代码删除
- 在这个场景中，A系统和其他系统严重耦合，A系统产生一条比较关键的数据，很多系统都需要A系统将这个数据发送过来，那么A系统就需要考虑BCD三个系统如果挂了怎么办？要不要重发？要不要把消息保存起来？
- 如果使用MQ，A系统产生一条数据，发送到MQ里面，哪个系统需要数据就自己去MQ里面消费；如果新系统需要数据，直接从MQ里面消费即可；如果某个系统不需要这条数据，就取消对MQ的消费即可
- 这样一来，A系统就不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑其他系统是否调用成功、失败超时等情况

![2](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181057570.png)

通过一个MQ，Pub/Sub发布订阅消息这么一个模型，A系统就和其他系统彻底解耦了

## 1.2 异步

![3](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181058687.png)

- 有这么个场景：A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms，最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s；用户通过浏览器发起请求，等待个1s，这几乎是不可接受的
- 如果使用MQ，那么A系统连续发送3条消息到MQ队列中，假如耗时5ms，A系统从接受一个请求到返回响应给用户，总时长是3+5=8ms，那么对于用户而言他的体验感就很好

![4](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181058310.png)

## 1.3 削峰

![5](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181058524.png)

- 有这么个场景：每天0:00 到 12:00，A 系统每秒并发请求数量就 50 个，结果每次一到 12:00 ~ 13:00 ，每秒并发请求数量突然会暴增到 5k+ 条，但是系统是直接基于MySQL 的，大量的请求涌入 MySQL，每秒钟对 MySQL执行约 5k 条 SQL
- 一般的 MySQL，扛到每秒 2k 个请求就差不多了，如果每秒请求到 5k 的话，可能就直接导致系统崩溃，用户也就没法再使用系统了
- 但是高峰期一过，到了下午的时候，就成了低峰期，可能也就 1w 的用户同时在网站上操作，每秒中的请求数量可能也就 50 个请求，对整个系统几乎没有任何的压力
- 如果使用 MQ，每秒 5k 个请求写入 MQ，A 系统每秒钟最多处理 2k 个请求，因为 MySQL 每秒钟最多处理 2k个；A 系统从 MQ 中慢慢拉取请求，每秒钟就拉取 2k个请求，不要超过自己每秒能处理的最大请求数量就行，这样下来，哪怕是高峰期的时候，A 系统也绝对不会挂掉，而 MQ 每秒钟 5k 个请求进来，就 2k 个请求出去，结果就导致在中午高峰期（1 个小时），可能有几十万甚至几百万的请求积压在 MQ 中

![6](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181058156.png)

- 这个短暂的高峰期积压是 ok 的，因为高峰期过了之后，每秒钟就 50 个请求进 MQ，但是 A 系统依然会按照每秒 2k 个请求的速度在处理；所以说，只要高峰期一过，A 系统就会快速将积压的消息给解决掉

# 二、消息队列的优缺点

- 优点
  - 解耦
  - 异步
  - 削峰
- 缺点
  - **系统可用性降低**：系统引入的外部依赖越多，越容易挂掉；本来使用A 系统调用 BCD 三个系统的接口就好了，没什么问题，你加个MQ 进来，万一 MQ 挂了怎么办，MQ 一挂，整套系统就崩溃了
  - **系统复杂度提高**：加个 MQ 进来，你怎么保证消息有没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？
  - **一致性问题**：A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，你这数据就不一致了
  - 所以消息队列实际上是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，做好之后，你会发现系统复杂度提升了一个数量级，也许是复杂了10倍

# 三、如何保证Kafka的高可用

- Kafka的架构：由多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据
- 这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据
- Kafka0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言
- 比如说，我们假设创建了一个topic，指定其partition数量是3个，分别在三台机器上；但是，如果第二台机器宕机了，会导致这个topic的1/3的数据就丢失了，因此这个是做不到高可用的

![7](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181059867.png)

- Kafka0.8以后，提供了HA机制，就是副本机制；每个partition的数据都会同步到其他机器上，形成自己的多个副本

![8](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181059636.png)

Kafka0.8以后，HA机制：均匀的将一个partition的所有副本分布在不同的机器上，这样才可以提高容错性

- 所有副本会选举一个leader出来，那么生产和消费都跟这个leader打交道，其他的副本就是follower
  - 写的时候：生产者就写leader，然后leader将数据落盘，接着其他follower自己主动从leader来pull数据，一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者（当然，这只是其中一种模式，还可以适当调整这个行为）
  - 读的时候：直接读leader上的数据即可，但是只有当一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到（即HW所记录的那个位置）
- 如果某个broker宕机了，那么broker上面的partition在其他的机器上有副本，如果这个宕机的broker上面有某个partition的leader，那么此时会从follower中重新选举一个新的leader出来，继续读写那个新的leader即可，这就是所谓的高可用性了

# 四、如果保证消息不被重复消费？或者说，如何保证消息消费的幂等性

## 4.1 Kafka中的重复消费例子

- Kafka有个offset的概念，就是每个消息写进去，都有一个offset，代表消息的序号，然后消费者消费了数据之后，每隔一段时间（定时定期）会把自己消费过的消息的offset提交一下，表示“我已经消费过了，下次我要是重启什么的，就让我继续从上次消费到的offset来继续消费”
- 但是，我们要是在重启的时候，碰到点着急的，直接kill进行了，再重启；这会导致消费者有些消息处理了，但是没来得及提交offset，这样重启之后，少数消息会再消费一次
- 例如有这么个场景：数据1、2、3一次进入Kafka，Kafka会给这三条数据每条分配一个 offset，代表这条数据的序号，我们就假设分配的 offset 依次是 152、153、154；消费者从 kafka 去消费的时候，也是按照这个顺序去消费；假如当消费者消费了 offset=153 的这条数据，刚准备去提交 offset 到 ，此时消费者进程被重启了，那么此时消费过的数据 1、2 的 offset 并没有提交，kafka 也就不知道你已经消费了 offset=153 这条数据，那么重启之后，消费者会要求Kafka把上次我消费到的那个地方后面的数据继续传递过来；而由于之前的offset没有提交成功，那么数据1、2会再次传过来，如果此时消费者没有去重的话，那么就会导致重复消费

![9](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181059294.png)

- 重复消费是有可能发生的，所以我们要考虑的是重复消费之后，怎么保证幂等性
- 假设你有个系统，消费一条消息就往数据库里插入一条数据，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下是否已经消费过了，若是就直接扔了，这样不就保留了一条数据，从而保证了数据的正确性
- 一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性
- 幂等性，通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错

## 4.2 怎么保证幂等性

- 其实还得结合业务来思考
- 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下
- 比如你是写 Redis，那没问题了，反正每次都是set，天然幂等性
- 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可
- 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据
- 对于Kafka的幂等性，可以参考[1、Kafka知识点](./1、Kafka知识点.md)

# 五、如何保证消息的顺序性

- 比如说我们建了一个 topic，有三个partition。生产者在写的时候，其实可以指定一个 key，比如说我们指定了某个订单 id 作为key，那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的
- 消费者从 partition 中取出来数据的时候，也一定是有顺序的。到这里，顺序还是 ok 的，没有错乱。接着，我们在消费者里可能会搞多个线程来并发处理消息。因为如果消费者是单线程消费处理，而处理比较耗时的话，比如处理一条消息耗时几十 ms，那么 1 秒钟只能处理几十条消息，这吞吐量太低了。而多个线程并发跑的话，顺序可能就乱掉了

![10](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181118647.png)

- 解决方案：

  - 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个
  - 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性

  ![11](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181118739.png)

# 六、消息队列的延时以及过期失效问题？消息队列满了或几百万积压该怎么处理

## 6.1 针对的场景

- 可能是你的消费端出了问题，不消费了
- 或者消费的速度极其慢，可能你的消息队列集群的磁盘都快写满了，都没有人消费
- 举个例子：消费端每次消费之后都要写mysql，结果mysql挂了，消费端就不动了；或者消费速度极其慢

## 6.2 大量消息积压

- 修复消费者的问题
  - 一个消费者一秒是 1000 条，一秒 3 个消费者是 3000条，一分钟就是 18 万条
  - 所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来
- 临时紧急扩容
  - 先修复消费者的问题，确保其恢复消费速度，然后将现有消费者都停掉
  - 新建一个topic，partition是原来的10倍，临时建立好原先10倍的队列数量
  - 然后写一个临时分发数据的消费者程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的队列
  - 接着临时征用10倍的机器来部署消费者，每一批消费者消费一个临时队列的数据；这种做法相当于临时将队列资源和消费者资源扩大10倍，以正常的10倍速度来消费数据
  - 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原先的消费者机器来消费消息

## 6.3 消息过期失效

- 批量重导：大量积压的时候，就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来
- 假设 1 万个订单积压在 mq 里面，没有处理，其中1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次

## 6.4 消息快写满了

- 临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，再补数据

# 七、消息队列的架构设计

- 首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？
- 其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路
- 其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka的高可用保障机制。多副本 -> leader & follower-> broker 挂了重新选举 leader 即可对外服务
- 能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案
- 可以讲解Kafka的设计框架

# 八、如何保证消息的顺序性（全局有序）

> Kafka只能保证分区内的有序性

- 全局顺序就目前的应用范围来讲，可以列举出来的也就限于binlog日志传输，如mysql binlog日志传输要求全局的顺序，不能有任何的乱序。这种的解决办法通常是最为保守的方式：
  - 全局使用一个生产者
  - 全局使用一个消费者（并严格到一个消费线程）
  - 全局使用一个分区（当然不同的表可以使用不同的分区或者topic实现隔离与扩展）

# 九、Kafka的架构

![12](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181118359.png)

- Producer：消息生产者，就是向kafka broker发消息的客户端
- Consumer ：消息消费者，向kafka broker取消息的客户端
- Consumer Group （CG）：消费者组，由多个consumer组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者
- Broker ：一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic
- Topic ：可以理解为一个队列，生产者和消费者面向的都是一个topic
- Partition：为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列
- Replica：副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower
- leader：每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader
- follower：每个分区多个副本中的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的follower

# 十、Kafka生产者写入数据过程

- Kafka的Producer发送消息采用的是异步发送的方式
- 在消息发送的过程中，涉及到了两个线程——main线程和Sender线程，以及一个线程共享变量——RecordAccumulator
- main线程将消息发送给RecordAccumulator，Sender线程不断从RecordAccumulator中拉取消息发送到Kafka broker

![13](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181119325.png)

- 相关参数：
  - batch.size：只有数据积累到batch.size之后，sender才会发送数据
  - [linger.ms](http://linger.ms/)：如果数据迟迟未达到batch.size，sender等待linger.time之后就会发送数据

# 十一、Kafka为什么使用pull消息的机制

> consumer采用pull模式从broker中读取消息

- push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞
- 而pull模式则可以根据consumer的消费能力以适当的速率消费消息
- pull模式不足之处是，如果kafka没有数据，消费者可能会陷入循环中，一直返回空数据。针对这一点，Kafka的消费者在消费数据时会传入一个时长参数timeout，如果当前没有数据可供消费，consumer会等待一段时间之后再返回，这段时长即为timeout

## 十二、对Kafka的理解？Kafka的架构？Kafka的基本原理

- Kafka有broker、producer、consumer、topic和partition，把这五个的原理和底层讲一下

## 12.1 Kafka工作流程

- Kafka中消息是以topic进行分类的，生产者生产消息，消费者消费消息，都是面向topic的
- topic是逻辑上的概念，而partition是物理上的概念，每个partition对应于一个log文件，该log文件中存储的就是producer生产的数据；producer生产的数据会被不断追到到该log文件末端，且每条数据都有自己的offset；消费者组中的每个消费者，都会实时记录自己消费到了哪个offset，以便出错恢复时，从上次的位置继续消费

## 12.2 Kafka文件存储机制

![14](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181119646.png)

- 由于生产者生产的消息会不断追加到log文件末尾，为了防止log文件过大导致数据定义效率低下，Kafka采取了分片和索引机制，将每个partition分为多个segment

- 每个segment对应两个文件——”.index“文件和".log"文件

- 这些文件位于一个文件夹下，该文件夹的命令规则为：topic + 分区序号

  - 例如：first这个topic有三个分区，则其对应的文件夹为first-0、first-1、first-2

  ![15](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181119466.png)

- index和log文件以当前segment的第一条消息的offset命名

![16](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181119035.png)

- ".index"文件存储大量的索引信息，".log"文件存储大量的数据，索引文件中的元数据指向对应数据文件中message中的物理偏移地址

# 十三、Kafka的消费者组和分区之间有什么关系

- 消费者组由多个consumer组成
- 消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者消费
- 消费者组之间互不影响
- 所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者

# 十四、Kafka的分区由哪些方式（针对生产者）

> 我们需要将producer发送的数据封装成一个ProducerRecord对象

![17](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181120330.png)

- 指明partition的情况下：直接将指明的值作为partition值
- 没有指明partition值但有key的情况下：将key的hash值与topic的partition数进行取余得到partition值
- 既没有 partition 值又没有 key 值的情况下：第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 RoundRobin算法

# 十五、消费者分区分配策略

- 一个consumer group中有多个consumer，一个 topic有多个partition，所以必然会涉及到partition的分配问题，即确定哪个partition由哪个consumer来消费

- Kafka有两种分配策略，一是roundrobin，一是range

- **roundrobin：轮询方式**

  ![1](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181121834.png)

- **range**

  ![2](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181121420.png)

# 十六、Kafka消息丢失怎么办

- 设置ack=all，即保证leader和follower都落盘成功之后才发送ack给Producer
- 数据的可靠性保证

# 十七、Kafka中的消费者如何获取到offset？offset是在哪管理的

- 由于consumer在消费过程中可能会出现断电宕机等故障，consumer恢复后，需要从故障前的位置的继续消费，所以consumer需要实时记录自己消费到了哪个offset，以便故障恢复后继续消费
- Kafka 0.9版本之前，consumer默认将offset保存在Zookeeper中，从0.9版本开始，consumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets

# 十八、同一个partition中数据是否有序

- 有序的，每个partition使用队列进行存储，也就是局部有序
- 若要做到全局有序，只能够使用一个分区

# 十九、Kafka如何保证高吞吐

- **分区**

  - Kafka中的topic的内容可以被分为多份partition存在，每个partition下记录的数据又分为多个segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加并行操作的能力

- **顺序写磁盘**

  - Kafka的producer生产数据，要写入到log文件中，写的过程是一直追加到文件末端，为顺序写
  - 顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写
  - 官网有数据表明，同样的磁盘，顺序写能到到600M/s，而随机写只有100k/s。这与磁盘的机械机构有关，顺序写之所以快，是因为其省去了大量磁头寻址的时间

- **零拷贝**

  ![1](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181122066.png)

  - 零拷贝系统调用机制，就是跳过用户缓冲区的拷贝，建立一个磁盘空间和内存的直接映射，数据不再直接复制到用户态缓冲区

- **批量发送**

  - Kafka允许进行批量发送消息，producer发送消息的时候，可以将消息缓存到本地，等到了固定条件发送到Kafka

    - 等消息条数到固定条数
    - 一段时间发送一次

    ![2](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181123095.png)

# 二十、零拷贝具体怎么做的

![18](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181122060.png)

![19](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181122124.png)

# 二十一、Kafka在什么地方用到zookeeper

- Kafka将元数据信息保存在Zookeeper中，但是发送给Topic本身的数据是不会发到Zk上的
- kafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置
- broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新
- 而客户端会在zookeeper上注册相关的watcher；一旦zookeeper发生变化，客户端能及时感知并作出相应调整。这样就保证了添加或去除broker时，各broker间仍能自动实现负载均衡
- Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作
- Controller的管理工作都是依赖于Zookeeper的

# 二十二、Kafka怎么保证消费的时序性

- 为了保证一个消费者中多个线程去处理时，不会使得消息的顺序被打乱，则可以在消费者中，消息分发至不同的线程时，加一个队列，消费者去做hash分发，将需要放在一起的数据，分发至同一个队列中，最后多个线程从队列中取数据

# 二十三、Kafka作为消息队列和Redis的区别

- 订阅功能的分组
  - Redis 发布订阅除了表示不同的 topic 外，并不支持分组
  - Kafka 中发布一个内容，多个订阅者可以分组，同一个组里只有一个订阅者会收到该消息，这样可以用作负载均衡
- redis是内存数据库，只是它的list数据类型刚好可以用作消息队列而已
- kafka是消息队列，消息的存储模型只是其中的一个环节，还提供了消息ACK和队列容量、消费速率等消息相关的功能，更加完善
- 处理数据大小的级别不同

# 二十四、Kafka怎么进行数据备份

- Kafka的备份的单元是partition，也就是每个partition都会有leader partiton和follow partiton
- 其中leader partition是用来进行和producer进行写交互，follower向leader进行拉数据进行同步，从而保证数据的冗余，防止数据丢失的目的

![20](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181123792.png)

# 二十五、Kafka的ISR机制

- leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护
- 如果一个follower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其从ISR中移除
- 当ISR中所有Replica都向Leader发送ACK时，leader才commit

# 二十六、Kafka如何保证数据的不重复和不丢失

- 数据丢失情况
  - 使用同步模式的时候，有3种状态保证消息被安全生产，在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失
  - 还有一种情况可能会丢失消息，就是使用异步模式的时候，当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉
- 不丢失
  - 生产者数据不丢失
    - 生产者发送数据有同步方式和异步方式
    - 在同步方式下发送数据，在发送的时候会产生阻塞，等待ack反馈，acks有三个参数0, 1，all，acks参数设置为0表示不等待反馈，表示不需要等待kafka完成同步确认接收消息，风险很大，数据可能丢失，设置为1表示必须kafka集群中的leader节点接收到消息并确认当前的生产者可以发送下一条消息，但是如果这个时候leader挂掉了，集群中尚未完成其他机器的同步，这时候导致数据丢失，设置为all表示等待kafka集群所有节点反馈，可以保证不丢失数据，三种参数的性能上有差异，比如一些允许丢失的消息，又想提升吞吐量，可以配置成0
    - 在异步模式下，如果消息发出去了，但还没有收到确认的时候，缓冲池满了，在配置文件中设置成不限制阻塞超时的时间，也就说让生产端一直阻塞，这样也能保证数据不会丢失
  - 消费者数据不丢失
    - 如果使用了storm，要开启storm的ackfail机制
    - 如果没有使用storm，关闭自动提交，手工提交offset，确认数据被完全处理之后，再更新offset值
    - 低级API中需要手动控制offset值
- 数据不重复
  - 去重：将消息的唯一标识保存到外部介质中，每次消费处理时判断是否处理过
  - 不管：大数据场景中，报表系统或者日志信息丢失几条都无所谓，不会影响最终的统计分析结果

# 二十七、Kafka如何清理过期数据

- 日志的真正清理时间是当删除的条件满足以后，日志将被“删除”，但是这里的删除其实只是将该日志进行了“delete”标注，文件只是无法被索引到了而已
- 但是文件本身，仍然是存在的，只有当过了`log.segment.delete.delya.ms`这个时间以后，文件才会被真正的从文件系统中删除

# 二十八、一条message中包含哪些信息

- 一个Kafka的message由一个固定长度的header和一个变长的消息体body组成
- header部分由一个字节的magic（文件格式）和四个字节的CRC32（用于判断body消息体是否正常）构成
- 当magic的值为1的时候，会在magic和CRC32之间多一个字节的而数据：attributes（保存一些相关属性，比如是否压缩、压缩格式等等）
- 如果magic的值为0，那么不存在attributes属性
- body是由N个字节构成的一个消息体，包含了具体的key/value消息

# 二十九、Kafka主要用于哪个场景下

- 日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等
- 消息系统：解耦和生产者和消费者、缓存消息等
- 用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘
- 运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告
- 流式处理：比如spark streaming和storm
- 事件源

# 三十、Kafka的特点

- 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作
- 可扩展性：kafka集群支持热扩展
- 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
- 高并发：支持数千个客户端同时读写

# 三十一、Kafka在zookeeper中存储的数据

[apache kafka系列之在zookeeper中存储结构_李志涛的专栏-CSDN博客_kafka zookeeper](https://blog.csdn.net/lizhitao/article/details/23744675)

# 三十二、Kafka的三种消息传递语义

- At least once：可能会重传数据，有可能出现数据被重复处理的情况
- At most once：可能会出现数据丢失情况
- Exactly once：并不是指真正只传输1次，只不过有一个机制，确保不会出现“数据被重复处理”和“数据丢失”的情况
- 整体的消息投递语义需要Producer端和Consumer端两者来保证。KAFKA默认是At most once，也可以通过配置事务达到Exactly once，但效率很低，不推荐

# 三十三、Kafka的持久化

- kafka使用文件存储消息(append only log)，这就直接决定kafka在性能上严重依赖文件系统的本身特性
- 且无论任何OS下，对文件系统本身的优化是非常艰难的
- 文件缓存/直接内存映射等是常用的手段，因为kafka是对日志文件进行append操作,因此磁盘检索的开支是较小的
- 同时为了减少磁盘写入的次数，broker会将消息暂时buffer起来，当消息的个数(或尺寸)达到一定阀值时，再flush到磁盘，这样减少了磁盘IO调用的次数
- 对于kafka而言，较高性能的磁盘将会带来更加直接的性能提升

# 二十四、为什么半数以上同意才能选出leader

- 防止脑裂

# 二十五、数据倾斜怎么处理

- 为 Producer 选择合适的 Key
- 假设一个场景，我们需要将每个用户的 Page View 信息给存入 Kafka ，此时我以 userId 来作为 key
- 理想情况下这种选择是不会错的，但如果有爬虫来模拟用户操作时，此用户的访问量可能是正常用户的百倍甚至千倍，这时，虽然userId 作为 key 是均匀分布的，但其背后的数据量却并不一定是均匀分布的，就可能产生数据倾斜的情况，导致各个 Partition 数据量分布不均匀

# 二十六、Kafka为什么要以消费者组进行消费

![21](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181124544.png)

# 二十七、当消费者组里有消费者挂掉以后会发生什么

rebalance

# 二十八、Kafka中当发送的Message中key为null时会发往哪个分区

- 当发送的key为null时，此时会随机的选择一个partition作为发送的分区，并且会将这个partition的id存储在一个缓存里面，之后再出现为null的key时直接只用缓存中的这个partition
- 这个缓存会每隔一段时间就清空，清空之后，当再次出现key为null的时候会再此随机的选择一个partition作为发送的分区，并且再次将这个值发送到缓存里面

# 二十九、offset存储

本地和zookeeper

# 三十、Kafka高低阶消费者

- 高阶消费者会导致数据丢失和数据重复

# 三十一、为什么最新版本不用zookeeper来维护offset

# 三十二、Kafka的最小工作单元

- 就是说我们在写代码的时候，要用kafka的时候。我们需要使用那些最基础的组件，比如生产者、消费者、主题、偏移量 等等

# 三十三、Kafka的ack机制？集群中的ack是怎么实现的