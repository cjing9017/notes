# HashMap

# 一、HashMap与哈希表简介

## 2.1 哈希表简介

- 核心是基于哈希值的桶和链表
- O(1)的平均查找、插入和删除时间
- 致命缺陷是哈希值的碰撞（collision）

![1](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181143755.png)

# 二、Java7 HashMap

- 经典的哈希表实现：数组+链表

- **默认桶的大小为1 << 4（必须为2的n次方）**

  ```java
  static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16
  ```

  - 如果桶的大小为2的n次方，那么我用hash值和2的n次方法减1做按位与操作，可以取到桶的所有位置，因为2的n次方减1上的二进制位都是1
  - 如果桶的大小不是2的n次方，那么2的n次方减1之后必定有不为1的二进制位，那就说明这个桶里面必然会有一些桶的位置取不到，永远为空

  ![2](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181143309.png)

- **默认桶的最大值为1 << 30**

  ```java
  static final int MAXIMUM_CAPACITY = 1 << 30;
  ```

- **默认负载因子为0.75**

  ```java
  static final float DEFAULT_LOAD_FACTOR = 0.75f;
  ```

  - 一般来说，默认的负载因子在时间和空间的复杂度上提供了良好的折中的平衡
  - 如果负载因子的值过大，会增加存储的数量，但是会增加查找的时间消耗（反映在HashMap中的绝对大多数操作，例如get和put方法）

- 只有在第一次往里面放数据的时候才会真正的开辟内存空间，避免造成空间的浪费

## 2.1 put方法

```java
public V put(K key, V value) {
    if (table == EMPTY_TABLE) {
        inflateTable(threshold);
    }
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key);
    int i = indexFor(hash, table.length);
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }

    modCount++;
    addEntry(hash, key, value, i);
    return null;
}

/**
 * An empty table instance to share when the table is not inflated.
 */
static final Entry<?,?>[] EMPTY_TABLE = {};
```

- 首先检测等于EMPTY_TABLE（一个静态的空的表实例）

- **意味着如果表没有初始化的时候，调用inflateTable()进行大小的扩张**

  ```java
  private void inflateTable(int toSize) {
      // Find a power of 2 >= toSize
      int capacity = roundUpToPowerOf2(toSize);
  
      threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1);
      table = new Entry[capacity];
      initHashSeedAsNeeded(capacity);
  }
  
  private static int roundUpToPowerOf2(int number) {
      // assert number >= 0 : "number must be non-negative";
      return number >= MAXIMUM_CAPACITY
              ? MAXIMUM_CAPACITY
              : (number > 1) ? Integer.highestOneBit((number - 1) << 1) : 1;
  }
  ```

  - 会将传入的桶的大小进行向上扩张为2的n次方
  - 如果传入的大小大于或等于最大值，则直接使用最大值1 << 30
  - 如果传入的大小小于或等于1，则大小定义为1
  - 否则我们找到这个大小的最左边的一个1，那么比这个数大的2的n次方就是把这个位置的1往左移动一位

- 如果key为空，则放入一个专门容纳空值的桶的位置

- **接着计算key的hash值**

  ```java
  final int hash(Object k) {
      int h = hashSeed;
      if (0 != h && k instanceof String) {
          return sun.misc.Hashing.stringHash32((String) k);
      }
  
      h ^= k.hashCode();
  
      // This function ensures that hashCodes that differ only by
      // constant multiples at each bit position have a bounded
      // number of collisions (approximately 8 at default load factor).
      h ^= (h >>> 20) ^ (h >>> 12);
      return h ^ (h >>> 7) ^ (h >>> 4);
  }
  ```

  - 复杂操作的目的是为了防止设计不良的hash函数
  - 假如你提供了一个随机的种子hashSeed，并且这个key的类型是String的话，提供一种不是String的哈希算法来计算String的哈希值，来避免一种潜在的攻击

- **将hash值映射到具体的桶的位置**

  - 第一种方法：取余运算%
    - 缺点：1）负数求余是负数（所以需要将负数转为正数）；2）速度较慢（因为取余的本质是不停的在做减法）

```java
static int indexFor(int h, int length) {
    // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2";
    return h & (length-1);
}
```

- 这里计算桶的位置利用的是哈希值和桶的大小-1做按位与的操作
- JDK7是经典的链表实现，所以他在取得桶的位置之后，需要去遍历链表；这里的Entry是链表中的一个结点

```java
for (Entry<K,V> e = table[i]; e != null; e = e.next) {
    Object k;
    if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
        V oldValue = e.value;
        e.value = value;
        e.recordAccess(this);
        return oldValue;
    }
}

static class Entry<K,V> implements Map.Entry<K,V> {
    final K key;
    V value;
    Entry<K,V> next;
    int hash;
```

- 假如找到了相同的key，则用新的value覆盖之间旧的value，并返回旧的value值
- 否则没有找到的话，就往链表里面添加一个结点

```java
void addEntry(int hash, K key, V value, int bucketIndex) {
    if ((size >= threshold) && (null != table[bucketIndex])) {
        resize(2 * table.length);
        hash = (null != key) ? hash(key) : 0;
        bucketIndex = indexFor(hash, table.length);
    }

    createEntry(hash, key, value, bucketIndex);
}

void resize(int newCapacity) {
    Entry[] oldTable = table;
    int oldCapacity = oldTable.length;
    if (oldCapacity == MAXIMUM_CAPACITY) {
        threshold = Integer.MAX_VALUE;
        return;
    }

    Entry[] newTable = new Entry[newCapacity];
    transfer(newTable, initHashSeedAsNeeded(newCapacity));
    table = newTable;
    threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);
}
```

- **在这个函数中包含了负责扩容的一个职责**

  - 首先，进行一次Rehashes的操作（因为桶的大小发生改变了，变了旧的容量的2倍，保证扩容之后的大小还是2的n次方）
  - 将原有的结点迁移到另外新开辟的更大的空间中

  ```java
  void transfer(Entry[] newTable, boolean rehash) {
      int newCapacity = newTable.length;
      for (Entry<K,V> e : table) {
          while(null != e) {
              Entry<K,V> next = e.next;
              if (rehash) {
                  e.hash = null == e.key ? 0 : hash(e.key);
              }
              int i = indexFor(e.hash, newCapacity);
              e.next = newTable[i];
              newTable[i] = e;
              e = next;
          }
      }
  }
  ```

  - 对于旧表里的每一个桶，遍历这个桶中的链表上的所有结点，计算新的hash值，并根据这个hash值计算新表中桶的位置后放入相应位置中
  - 这里采用的是一个头插法

- 扩容发生在

  - 假如此时存储的数量大于阈值（=桶的大小*负载一因子）

## 2.2 问题

- CVE-2011-4858

- Tomcat邮件组的讨论

- **非常容易碰到的死锁**

  - 并发环境中易死锁：[疫苗：Java HashMap的死循环 | | 酷 壳 - CoolShell](https://coolshell.cn/articles/9606.html)

  ![3](https://cdn.jsdelivr.net/gh/cjing9017/Files@main/img/202305181144582.png)

- **潜在的安全隐患**

  - 可以通过精心构造的恶意请求引发DoS攻击
  - 链表性能退化分析（所有结点计算的桶位置都在同一个地方，是的哈希表退化为了链表），参考String中的hash值的计算方法

  ```java
  public int hashCode() {
      int h = hash;
      if (h == 0 && value.length > 0) {
          char val[] = value;
  
          for (int i = 0; i < value.length; i++) {
              h = 31 * h + val[i];
          }
          hash = h;
      }
      return h;
  }
  ```

# 三、Java8 HashMap

- 首先从代码量上来看，java8相比于java7来说代码量膨胀了将近1倍
- 默认的初始容量1 << 4
- 默认的最大容量1 << 30
- 默认的负载因子0.75

```java
/**
 * The bin count threshold for using a tree rather than list for a
 * bin.  Bins are converted to trees when adding an element to a
 * bin with at least this many nodes. The value must be greater
 * than 2 and should be at least 8 to mesh with assumptions in
 * tree removal about conversion back to plain bins upon
 * shrinkage.
 */
static final int TREEIFY_THRESHOLD = 8;

/**
 * The bin count threshold for untreeifying a (split) bin during a
 * resize operation. Should be less than TREEIFY_THRESHOLD, and at
 * most 6 to mesh with shrinkage detection under removal.
 */
static final int UNTREEIFY_THRESHOLD = 6;

/**
 * The smallest table capacity for which bins may be treeified.
 * (Otherwise the table is resized if too many nodes in a bin.)
 * Should be at least 4 * TREEIFY_THRESHOLD to avoid conflicts
 * between resizing and treeification thresholds.
 */
static final int MIN_TREEIFY_CAPACITY = 64;
```

- 当桶里面是链表的时候，超过TREEIFY_THRESHOLD时会使用红黑树

- 当桶里面时红黑树的时候，小于UNTREEIFY_THRESHOLD的时候退化为链表

- 要将链表转为红黑树使用的前提是桶的容量最小为MIN_TREEIFY_CAPACITY

- **为什么从链表转为红黑树的阈值是8**

  ```java
  * Because TreeNodes are about twice the size of regular nodes, we
   * use them only when bins contain enough nodes to warrant use
   * (see TREEIFY_THRESHOLD). And when they become too small (due to
   * removal or resizing) they are converted back to plain bins.  In
   * usages with well-distributed user hashCodes, tree bins are
   * rarely used.  Ideally, under random hashCodes, the frequency of
   * nodes in bins follows a Poisson distribution
   * (<http://en.wikipedia.org/wiki/Poisson_distribution>) with a
   * parameter of about 0.5 on average for the default resizing
   * threshold of 0.75, although with a large variance because of
   * resizing granularity. Ignoring variance, the expected
   * occurrences of list size k are (exp(-0.5) * pow(0.5, k) /
   * factorial(k)). The first values are:
   *
   * 0:    0.60653066
   * 1:    0.30326533
   * 2:    0.07581633
   * 3:    0.01263606
   * 4:    0.00157952
   * 5:    0.00015795
   * 6:    0.00001316
   * 7:    0.00000094
   * 8:    0.00000006
   * more: less than 1 in ten million
  ```

  - 桶中结点的分布是呈现参数为0.5的泊松分布
  - 同一个桶中有1个结点的概述是0.6，有8个结点的概率是0.00000006，那么超过8个结点的概率小于千万分之一的

## 3.1 put方法

```java
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}

static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

- 这里的hash值得计算方法将key得hashCode得低16位和它的高16位进行异或运算（为了防止说有一堆得hash值，他们只有高位不同，低位相同；）

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                 boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    else {
        Node<K,V> e; K k;
        if (p.hash == hash &&
            ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        else {
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    p.next = newNode(hash, key, value, null);
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}
```

- 首先判断一下如果还没有进行初始化的话，先进行初始化

- 如果找到这个key所在的桶的位置的中没有结点，则往里面放入第一个新的结点

- 否则判断

  - 如果当前第一个结点就是我要找的那个key，直接把它覆盖掉

  - 如果这个结点是一个树结点，则执行树结点的插入操作

  - 否则的话，桶中存储的就是链表了，在链表中进行遍历

    - 如果没有找的的话，旧往里面插入一个：这里要注意的是，如果链表结点个数+1（加上当前结点）≥ 转红黑树的阈值，就需要进行转红黑树的操作

    ```java
    final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            do {
                TreeNode<K,V> p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }
    ```

    - 找到的话，就将新值覆盖旧值

- 如果结点数量超过阈值，则进行扩容的操作

```java
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
}
```

- 这里的resize操作，保持了原有的顺序（但是仍然没有解决线程安全的问题）
- 有一个高位链表和一个低位链表，因为扩容之后高位增加了一个1，所以rehash之后新的位置要么和原来的相同，要么就移动到高位的那个地方
- 最后将高位链表和低位链表赋值给新的表

## 3.2 get方法

```java
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}

final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

- 首先也是计算hash值，找到桶的位置后
- 如果是第一个结点则直接返回
- 否则判断现在的结构是红黑树还是链表，根据结构不同去遍历相应的结构去查找

## 引入Lambda和函数式编程

- forEach
- compute系列
- Map的新API
  - **merge**
  - **replace**